import argparse
import logging
import sys
import time
import torch
import numpy as np

from pathlib import Path
from typing import List
from argparse import ArgumentError, ArgumentTypeError
from pathlib import Path

from . import utils
from ..model.train import train

logging.basicConfig(stream=sys.stdout, level=logging.INFO, format="%(message)s")
log = logging.getLogger(__name__)

def fit_model(args: argparse.Namespace, data: torch.Tensor, device: torch.device, num_gpus: int,
            master: bool, V: np.ndarray, pops: np.ndarray) -> None:
    """
    Wrapper function to start training
    """
    (epochs, batch_size, learning_rate, save_dir, hidden_size, name, seed, n_components) = (int(args.epochs), int(args.batch_size), float(args.learning_rate), args.save_dir, 
                                                                                        int(args.hidden_size), args.name, int(args.seed), int(args.n_components))
            
    if args.k is not None:
        K = int(args.k)
        min_k = None
        max_k = None
    else:
        min_k = int(args.min_k)
        max_k = int(args.max_k)
        K = None

    Ps, Qs, model = train(epochs, batch_size, learning_rate, K, seed, data, device, num_gpus, hidden_size, master, V, pops, min_k, max_k, n_components)
    
    if master:
        Path(save_dir).mkdir(parents=True, exist_ok=True)
        save_path = f'{save_dir}/{name}.pt'
        state_dict = {key: value for key, value in model.state_dict().items() if not key.startswith('decoders')}
        torch.save(state_dict, save_path)
        model.save_config(name, save_dir)
        utils.write_outputs(Qs, name, K, min_k, max_k, save_dir, Ps)

    return

"""
def perform_cross_validation(args: argparse.Namespace, trX: da.core.Array, device: torch.device, num_gpus: int, 
                             master: bool) -> None:
    
    Perform cross-validation and log the results.

    Args:
        args: A namespace object containing command-line arguments.
        trX: Training data.
        device: A string representing the device ('cuda:0', 'cpu', etc.)
        num_gpus: Number of GPUs.
    
    if master:
        log.info(f'Performing {args.cv}-fold cross-validation...')
    cv_obj = KFold(n_splits=args.cv, random_state=args.seed, shuffle=True)
    cv_errs = []
    
    for tr_idx, val_idx in tqdm(cv_obj.split(trX), desc="Cross-Validation"):
        with dask.config.set(**{'array.slicing.split_large_chunks': True}):
            trX_curr, valX_curr = trX[tr_idx], trX[val_idx]
        
        for k in range (args.k_range[0], args.k_range[1]):
            loglikelihood = fit_model(args, trX_curr, valX_curr, device, num_gpus, master, k=k)
            cv_errs.append(loglikelihood)
    
    cv_errs_reduced = utils.process_cv_loglikelihood(cv_errs)
    
    if master:
        for _, row in cv_errs_reduced.iterrows():
            log.info(f"CV error (K={int(row['K'])}): {row['cv_error_mean']:.5f} Â± {row['cv_error_std']:.3f}")
    
    utils.save_cv_error_plot(cv_errs_reduced, args.save_dir)
"""

def main(rank: int, argv: List[str], num_gpus: int, data: torch.Tensor, V: np.ndarray, pops: np.ndarray):
    """
    Training entry point
    """
    utils.ddp_setup('begin', rank, num_gpus)
    master = rank == 0
    
    try:
        if any(arg in argv for arg in ['-h', '--help']):
            if master:
                args = utils.parse_train_args(argv)
            return
        args = utils.parse_train_args(argv)
        
        if num_gpus>0:
            if torch.cuda.is_available():
                device = torch.device(f'cuda:{int(rank)}')
            elif torch.backends.mps.is_available():
                device = torch.device('mps')
            else:
                device = torch.device('cpu')
        else:
            device = torch.device('cpu')
        
        if master:
            log.info(f"    There are {args.num_cpus} CPUs and {num_gpus} GPUs available for this execution.")
            log.info("")
            if args.k is not None:
                log.info(f"    Running on K = {args.k}.")
            else:
                assert args.min_k is not None and args.max_k is not None, "You must provide either K or both min_k and max_k."
                min_k = int(args.min_k)
                max_k = int(args.max_k)
                assert min_k < max_k, f"min_k ({min_k}) must be less than max_k ({max_k})."
                log.info(f"    Running from K={min_k} to K={max_k}.")
            log.info("")
            Path(args.save_dir).mkdir(parents=True, exist_ok=True)
        
        t0 = time.time()
    
        #if args.cv is not None:
        #    perform_cross_validation(args, trX, device, num_gpus, master)   
        
        fit_model(args, data, device, num_gpus, master, V, pops)
        
        if master:
            t1 = time.time()
            log.info("")
            log.info(f"    Total elapsed time: {t1-t0:.2f} seconds.")
            log.info("")
        
        logging.shutdown()
        utils.ddp_setup('end', rank, num_gpus)
    
    except (ArgumentError, ArgumentTypeError) as e:
        if master:
            log.error(f"    Error parsing arguments")
        logging.shutdown()
        utils.ddp_setup('end', rank, num_gpus)
        if master:
            raise e
        
    except Exception as e:
        if master:
            log.error(f"    Unexpected error")
        logging.shutdown()
        utils.ddp_setup('end', rank, num_gpus)        
        if master:
            raise e
        
if __name__ == '__main__':
    main(sys.argv[1:])